# -*- coding: utf-8 -*-
"""Transfer_Learning_SkinCancer_CNN_1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11373WkB2sUs7oq8phC_mPa4grXsPiGuJ
"""

import numpy as np 
import pandas as pd
import os # for directories
import cv2
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
from keras.callbacks import ModelCheckpoint
from keras.callbacks import EarlyStopping
#from tensorflow.keras import 
from tensorflow.keras.models import Sequential
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import layers
from tensorflow.keras.layers import Conv2D
from tensorflow.keras.layers import MaxPooling2D

#print(os.getcwd())

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/gdrive')
# %cd /gdrive

# Commented out IPython magic to ensure Python compatibility.
# %ls /gdrive/MyDrive/5644_ML_Project/

from google.colab import drive
drive.mount('/content/drive')

# to get data
train_path = os.path.join('/gdrive/MyDrive/5644_ML_Project', 'Dataset_SkinCancer/train')
print(train_path)
test_path = os.path.join('/gdrive/MyDrive/5644_ML_Project', 'Dataset_SkinCancer/test')
print(test_path)

class_names = ['malignant', 'benign']
print("Classes",class_names)

print('Count of Train Images:')
for i in class_names:
    print(i +' Train'+ ':' + str(len(os.listdir(os.path.join(train_path, i)))))

    
print('Count of Test Images:')
for i in class_names:
    print(i +' Test'+ ':' + str(len(os.listdir(os.path.join(test_path, i)))))

train_datagen = ImageDataGenerator(rescale=1./255,validation_split=0.2) #,horizontal_flip=True)#)
test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
        train_path,
        target_size=(32,32),
        batch_size=16,
        class_mode='binary',
        subset='training')
validation_generator = train_datagen.flow_from_directory(
        train_path,
        target_size=(32,32),
        batch_size=10,
        class_mode='binary',
        subset='validation')
test_generator = test_datagen.flow_from_directory(
        test_path,
        target_size=(32,32),
        batch_size=8,
        class_mode='binary')

# CNN model

#def model_1 (Malignant_train_images, Malignant_test_images):
model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(64, (3,3), activation = "relu", padding='same', input_shape = (32,32,3), trainable=False),
    tf.keras.layers.MaxPooling2D(2,2),
    #tf.keras.layers.Dropout(0.25),
    tf.keras.layers.Conv2D(64, (3,3), padding='same', activation = "relu",  trainable=True),
    #tf.keras.layers.MaxPooling2D(2,2),
    #tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Conv2D(128, (3,3), padding='same', activation = "relu", trainable=True),
    #tf.keras.layers.MaxPooling2D(2,2),
    #tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(256,activation = "relu"),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(80,activation = "relu"),
    tf.keras.layers.Dense(1,activation = "sigmoid")
])


# load json and create model
# json_file = open('model.json', 'r')
# loaded_model_json = json_file.read()
# json_file.close()
#loaded_model = model_from_json(loaded_model_json)

# load weights into new model
model.load_weights(r"/gdrive/MyDrive/5644_ML_Project/Models_1/cat_dogs_model_v1.h5")
print("Loaded model from disk")


    # training the model    
opt = keras.optimizers.Adam(learning_rate=0.00001)
model.summary()

model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['acc'])

# checkpoint
#filepath="best_weights_p_neuron-{epoch:02d}-{val_acc:.2f}.hdf5"
filepath = r"/gdrive/MyDrive/5644_ML_Project/Models_1/transfter_model_v2"
checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=0, save_best_only=True, mode='max')
early_stop = EarlyStopping (monitor='val_acc', mode='max', verbose=0, patience=10)
callbacks_list = [early_stop,checkpoint]

history = model.fit_generator(train_generator, validation_data = validation_generator, steps_per_epoch = 132,epochs = 100, validation_steps = 50, verbose = 1, callbacks=callbacks_list) #

   # return accuracy

loss , accuracy = model.evaluate(test_generator)

